<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
                "http://www.w3.org/TR/REC-html40/loose.dtd">
<html>
<head>
  <title>Description of ipopt</title>
  <meta name="keywords" content="ipopt">
  <meta name="description" content="IPOPT Call the IPOPT constrained, nonlinear solver.">
  <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
  <meta name="generator" content="m2html &copy; 2005 Guillaume Flandin">
  <meta name="robots" content="index, follow">
  <link type="text/css" rel="stylesheet" href="../../../m2html.css">
  <script type="text/javascript">
    if (top.frames.length == 0) { top.location = "../../../index.html"; };
  </script>
</head>
<body>
<a name="_top"></a>
<!-- ../../menu.html matRad --><!-- ../menu.html optimization --><!-- menu.html optimizer -->
<h1>ipopt
&nbsp;&nbsp;<img src="../../../mex.png" alt="Linux AMD Opteron, Windows 32, Windows 64" border="0" title="Linux AMD Opteron, Windows 32, Windows 64"></h1>

<h2><a name="_name"></a>Purpose <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="box">IPOPT Call the IPOPT constrained, nonlinear solver.</div>

<h2><a name="_synopsis"></a>Synopsis <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="box">This is a script file. </div>

<h2><a name="_description"></a>Description <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="fragment"><pre class="comment"> IPOPT Call the IPOPT constrained, nonlinear solver. 
   The basic function call is
   
     [x, info] = IPOPT(x0,funcs,options)

   The first input is either a matrix or a cell array of matrices. It
   declares the starting point for the solver.

   CALLBACK FUNCTIONS

   The second input must be struct containing function handles for various
   MATLAB routines. For more information on using functions and function
   handles in MATLAB, type HELP FUNCTION and HELP FUNCTION_HANDLE in the
   MATLAB prompt.

     funcs.objective (required)

     Calculates the objective function at the current point. It takes one
     point, the current iterate x. For example, the definition of the
     objective function for the Hock &amp; Schittkowski (H&amp;S) test problem #71
     (with 4 optimization variables) would be
 
         function f = objective (x)
           f = x(1)*x(4)*sum(x(1:3)) + x(3);
         
     funcs.gradient (required)

     Computes the gradient of the objective at the current point. It takes
     one input, the current iterate x. For H&amp;S test problem #71, the
     definition of the gradient callback would be

         function g = gradient (x)
           g = [ x(1)*x(4) + x(4)*sum(x(1:3))
                 x(1)*x(4)
                 x(1)*x(4) + 1
                 x(1)*sum(x(1:3)) ]; 

     funcs.constraints (optional)

     This function is only required if there are constraints on your
     variables. It evaluates the constraint functions at the current
     point. It takes one input, x. The return value is a vector of length
     equal to the number of constraints (it must be of the same length as
     options.cl and options.cu). For H&amp;S test problem #71, the
     callback definition would be

         function c = constraints (x)
           c = [ prod(x); sum(x.^2) ];

     funcs.jacobian (optional)
 
     This function is only required if there are constraints on your
     variables. Evaluates the Jacobian of the constraints at the current
     point. It takes one input, x. The output must always be an M x N
     sparse matrix, where M is the number of constraints and N is the
     number of variables. Type HELP SPARSE for more information on
     constructing sparse matrices in MATLAB. The definition of the
     callback function for H&amp;S test problem #71 would be

         function J = jacobian (x)
           sparse([ prod(x)./x; 2*x ]);

     Notice that the return value is a sparse matrix.

     funcs.jacobianstructure (optional)

     This function is only required if there are constraints on your
     variables. It takes no inputs. The return value is a sparse
     matrix whereby an entry is nonzero if and only if the Jacobian of
     the constraints is nonzero at ANY point. The callback function for
     the H&amp;S test problem #71 simply returns a 2 x 4 matrix of ones in
     the sparse matrix format:

         function J = jacobianstructure() 
           J = sparse(ones(2,4));

     funcs.hessian (optional)

     Evaluates the Hessian of the Lagrangian at the current point. It
     must be specified unless you choose to use the limited-memory
     quasi-Newton approximation to the Hessian (see below).
 
     The callback function has three inputs: the current point (x), a
     scalar factor on the objective (sigma), and the Lagrange multipliers
     (lambda), a vector of length equal to the number of constraints. The
     function should compute
                  
        sigma*H + lambda(1)*G1 + ... + lambda(M)*GM

     where M is the number of constraints, H is the Hessian of the
     objective and the G's are the Hessians of the constraint
     functions. The output must always be an N x N sparse, lower triangular
     matrix, where N is the number of variables. In other words, if X is
     the output value, then X must be the same as TRIL(X).

     Here is an implementation of the Hessian callback routine for the
     H&amp;S test problem #71:

         function H = hessian (x, sigma, lambda)
           H = sigma*[ 2*x(4)             0      0   0;
                       x(4)               0      0   0;
                       x(4)               0      0   0;
                       2*x(1)+x(2)+x(3)  x(1)  x(1)  0 ];
           H = H + lambda(1)*[    0          0         0         0;
                               x(3)*x(4)     0         0         0;
                               x(2)*x(4) x(1)*x(4)     0         0;
                               x(2)*x(3) x(1)*x(3) x(1)*x(2)     0  ];
           H = sparse(H + lambda(2)*diag([2 2 2 2]));
  
     funcs.hessianstructure (optional)
 
     This function serves the same purpose as funcs.jacobianstructure, but
     for the Hessian matrix. Again, it is not needed if you are using the
     limited-memory quasi-Newton approximation to the Hessian. It takes no
     inputs, and must return a sparse, lower triangular matrix. For H&amp;S
     test problem #71, the MATLAB callback routine is fairly
     straightforward:

         function H = hessianstructure() 
           H = sparse(tril(ones(4)));

     funcs.iterfunc (optional)

     An additional callback routine that is called once per algorithm
     iteration. It takes three inputs: the first is the current iteration
     of the algorithm, the second is the current value of the objective,
     and the third is a structure containing fields x, inf_pr, inf_du, mu,
     d_norm, regularization_size, alpha_du, alpha_pr, and ls_trials. This
     function should always return true unless you want IPOPT to terminate
     prematurely for whatever reason. If you would like to use the third
     input to iterfunc along with auxdata functionality, you will need to
     modify the appropriate section of ipopt_auxdata.m.

   OPTIONS

   The options are passed through the third input. What follows is a
   description of the fields you may optionally specify.

     options.lb  

     Specify lower bounds on the variables. It must have the same number
     of elements as x0. Set an entry to -Inf to specify no lower bound.

     options.ub

     Specify upper bounds on the variables. It must have the same number
     of elements as x0. Set an entry to Inf to specify no upper bound.

     options.cl, options.cu

     Set lower and upper bounds on the constraints. Each should be a
     vector of length equal to the number of constraints. As before, a
     bound is removed by setting the entry to -Inf or +Inf. An equality
     constraint is achieved by setting cl(i) = cu(i).

     options.auxdata

     Optionally, one may choose to pass additional auxiliary data to the
     MATLAB callback routines listed above through the function call. For
     instance, the objective callback function now takes two inputs, x and
     auxdata. The auxiliary data may not change through the course of the
     IPOPT optimization. The auxiliary data keep the same values as they
     possessed in the initial call. If you need variables that change over
     time, you may want to consider global variables (type HELP
     GLOBAL). See the lasso.m file in the examples subdirectory for an
     illustration of how the auxiliary data is passed to the various
     callback functions. Starting with Ipopt version 3.11, you must call
     ipopt_auxdata(x0,funcs,options) to use auxdata functionality.

     options.zl, options.zu, options.lambda

     These fields specify the initial value for the Lagrange multipliers,
     which is especially useful for &quot;warm starting&quot; the interior-point
     solver. They specify the Lagrange multipliers corresponding to the
     lower bounds on the variables, upper bounds on the variables, and
     constraints, respectively.

     options.ipopt

     Finally, you may also change the settings of IPOPT through this
     field. For instance, to turn off the IPOPT output, use the
     limited-memory BFGS approximation to the Hessian, and turn on the
     derivative checker, do the following:

       options.ipopt.print_level           = 0;
       options.ipopt.hessian_approximation = 'limited-memory';
       options.ipopt.derivative_test       = 'first-order';

     For more details, see the documentation on the IPOPT website.

   OUTPUTS

   If the solver successfully converges to a stationary point or terminated
   without an unrecoverable error, the function IPOPT outputs the candidate
   solution x. In all other cases, an error is thrown. It also outputs some
   additional information:

     info.zl, info.zu, info.lambda

     The value of the Lagrange multipliers at the solution. See the
     &quot;options&quot; for more information on the Lagrange multipliers.

     info.status

     Upon termination, this field will take on one of these following
     values (for a more up-to-date listing, see the IpReturnCodes.h header
     file in the IPOPT C++ source directory):

         0  solved
         1  solved to acceptable level
         2  infeasible problem detected
         3  search direction becomes too small
         4  diverging iterates
         5  user requested stop
     
        -1  maximum number of iterations exceeded
        -2  restoration phase failed
        -3  error in step computation
       -10  not enough degrees of freedom
       -11  invalid problem definition
       -12  invalid option
       -13  invalid number detected

      -100  unrecoverable exception
      -101  non-IPOPT exception thrown
      -102  insufficient memory
      -199  internal error

     info.iter, info.cpu

     Number of iterations and CPU time (in seconds) taken by the Ipopt run

   Finally, for more information, please consult the following webpages:

      http://www.cs.ubc.ca/~pcarbo/ipopt-for-matlab
      http://projects.coin-or.org/Ipopt

   Copyright (C) 2008 Peter Carbonetto. All Rights Reserved.
   This code is published under the Eclipse Public License.

   Author: Peter Carbonetto
           Dept. of Computer Science
           University of British Columbia
           September 19, 2008

   Downloaded binaries from http://www.coin-or.org/download/binary/Ipopt/I
   popt-3.11.8-linux64mac64win32win64-matlabmexfiles.zip on 3/22/2016</pre></div>

<!-- crossreference -->
<h2><a name="_cross"></a>Cross-reference information <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
This function calls:
<ul style="list-style-type:disc">
</ul>
This function is called by:
<ul style="list-style-type:disc">
<li><a href="matRad_OptimizerIPOPT.html" class="code" title="">matRad_OptimizerIPOPT</a>	</li></ul>
<!-- crossreference -->



<h2><a name="_source"></a>Source code <a href="#_top"><img alt="^" border="0" src="../../../up.png"></a></h2>
<div class="fragment"><pre>0001 <span class="comment">% IPOPT Call the IPOPT constrained, nonlinear solver.</span>
0002 <span class="comment">%   The basic function call is</span>
0003 <span class="comment">%</span>
0004 <span class="comment">%     [x, info] = IPOPT(x0,funcs,options)</span>
0005 <span class="comment">%</span>
0006 <span class="comment">%   The first input is either a matrix or a cell array of matrices. It</span>
0007 <span class="comment">%   declares the starting point for the solver.</span>
0008 <span class="comment">%</span>
0009 <span class="comment">%   CALLBACK FUNCTIONS</span>
0010 <span class="comment">%</span>
0011 <span class="comment">%   The second input must be struct containing function handles for various</span>
0012 <span class="comment">%   MATLAB routines. For more information on using functions and function</span>
0013 <span class="comment">%   handles in MATLAB, type HELP FUNCTION and HELP FUNCTION_HANDLE in the</span>
0014 <span class="comment">%   MATLAB prompt.</span>
0015 <span class="comment">%</span>
0016 <span class="comment">%     funcs.objective (required)</span>
0017 <span class="comment">%</span>
0018 <span class="comment">%     Calculates the objective function at the current point. It takes one</span>
0019 <span class="comment">%     point, the current iterate x. For example, the definition of the</span>
0020 <span class="comment">%     objective function for the Hock &amp; Schittkowski (H&amp;S) test problem #71</span>
0021 <span class="comment">%     (with 4 optimization variables) would be</span>
0022 <span class="comment">%</span>
0023 <span class="comment">%         function f = objective (x)</span>
0024 <span class="comment">%           f = x(1)*x(4)*sum(x(1:3)) + x(3);</span>
0025 <span class="comment">%</span>
0026 <span class="comment">%     funcs.gradient (required)</span>
0027 <span class="comment">%</span>
0028 <span class="comment">%     Computes the gradient of the objective at the current point. It takes</span>
0029 <span class="comment">%     one input, the current iterate x. For H&amp;S test problem #71, the</span>
0030 <span class="comment">%     definition of the gradient callback would be</span>
0031 <span class="comment">%</span>
0032 <span class="comment">%         function g = gradient (x)</span>
0033 <span class="comment">%           g = [ x(1)*x(4) + x(4)*sum(x(1:3))</span>
0034 <span class="comment">%                 x(1)*x(4)</span>
0035 <span class="comment">%                 x(1)*x(4) + 1</span>
0036 <span class="comment">%                 x(1)*sum(x(1:3)) ];</span>
0037 <span class="comment">%</span>
0038 <span class="comment">%     funcs.constraints (optional)</span>
0039 <span class="comment">%</span>
0040 <span class="comment">%     This function is only required if there are constraints on your</span>
0041 <span class="comment">%     variables. It evaluates the constraint functions at the current</span>
0042 <span class="comment">%     point. It takes one input, x. The return value is a vector of length</span>
0043 <span class="comment">%     equal to the number of constraints (it must be of the same length as</span>
0044 <span class="comment">%     options.cl and options.cu). For H&amp;S test problem #71, the</span>
0045 <span class="comment">%     callback definition would be</span>
0046 <span class="comment">%</span>
0047 <span class="comment">%         function c = constraints (x)</span>
0048 <span class="comment">%           c = [ prod(x); sum(x.^2) ];</span>
0049 <span class="comment">%</span>
0050 <span class="comment">%     funcs.jacobian (optional)</span>
0051 <span class="comment">%</span>
0052 <span class="comment">%     This function is only required if there are constraints on your</span>
0053 <span class="comment">%     variables. Evaluates the Jacobian of the constraints at the current</span>
0054 <span class="comment">%     point. It takes one input, x. The output must always be an M x N</span>
0055 <span class="comment">%     sparse matrix, where M is the number of constraints and N is the</span>
0056 <span class="comment">%     number of variables. Type HELP SPARSE for more information on</span>
0057 <span class="comment">%     constructing sparse matrices in MATLAB. The definition of the</span>
0058 <span class="comment">%     callback function for H&amp;S test problem #71 would be</span>
0059 <span class="comment">%</span>
0060 <span class="comment">%         function J = jacobian (x)</span>
0061 <span class="comment">%           sparse([ prod(x)./x; 2*x ]);</span>
0062 <span class="comment">%</span>
0063 <span class="comment">%     Notice that the return value is a sparse matrix.</span>
0064 <span class="comment">%</span>
0065 <span class="comment">%     funcs.jacobianstructure (optional)</span>
0066 <span class="comment">%</span>
0067 <span class="comment">%     This function is only required if there are constraints on your</span>
0068 <span class="comment">%     variables. It takes no inputs. The return value is a sparse</span>
0069 <span class="comment">%     matrix whereby an entry is nonzero if and only if the Jacobian of</span>
0070 <span class="comment">%     the constraints is nonzero at ANY point. The callback function for</span>
0071 <span class="comment">%     the H&amp;S test problem #71 simply returns a 2 x 4 matrix of ones in</span>
0072 <span class="comment">%     the sparse matrix format:</span>
0073 <span class="comment">%</span>
0074 <span class="comment">%         function J = jacobianstructure()</span>
0075 <span class="comment">%           J = sparse(ones(2,4));</span>
0076 <span class="comment">%</span>
0077 <span class="comment">%     funcs.hessian (optional)</span>
0078 <span class="comment">%</span>
0079 <span class="comment">%     Evaluates the Hessian of the Lagrangian at the current point. It</span>
0080 <span class="comment">%     must be specified unless you choose to use the limited-memory</span>
0081 <span class="comment">%     quasi-Newton approximation to the Hessian (see below).</span>
0082 <span class="comment">%</span>
0083 <span class="comment">%     The callback function has three inputs: the current point (x), a</span>
0084 <span class="comment">%     scalar factor on the objective (sigma), and the Lagrange multipliers</span>
0085 <span class="comment">%     (lambda), a vector of length equal to the number of constraints. The</span>
0086 <span class="comment">%     function should compute</span>
0087 <span class="comment">%</span>
0088 <span class="comment">%        sigma*H + lambda(1)*G1 + ... + lambda(M)*GM</span>
0089 <span class="comment">%</span>
0090 <span class="comment">%     where M is the number of constraints, H is the Hessian of the</span>
0091 <span class="comment">%     objective and the G's are the Hessians of the constraint</span>
0092 <span class="comment">%     functions. The output must always be an N x N sparse, lower triangular</span>
0093 <span class="comment">%     matrix, where N is the number of variables. In other words, if X is</span>
0094 <span class="comment">%     the output value, then X must be the same as TRIL(X).</span>
0095 <span class="comment">%</span>
0096 <span class="comment">%     Here is an implementation of the Hessian callback routine for the</span>
0097 <span class="comment">%     H&amp;S test problem #71:</span>
0098 <span class="comment">%</span>
0099 <span class="comment">%         function H = hessian (x, sigma, lambda)</span>
0100 <span class="comment">%           H = sigma*[ 2*x(4)             0      0   0;</span>
0101 <span class="comment">%                       x(4)               0      0   0;</span>
0102 <span class="comment">%                       x(4)               0      0   0;</span>
0103 <span class="comment">%                       2*x(1)+x(2)+x(3)  x(1)  x(1)  0 ];</span>
0104 <span class="comment">%           H = H + lambda(1)*[    0          0         0         0;</span>
0105 <span class="comment">%                               x(3)*x(4)     0         0         0;</span>
0106 <span class="comment">%                               x(2)*x(4) x(1)*x(4)     0         0;</span>
0107 <span class="comment">%                               x(2)*x(3) x(1)*x(3) x(1)*x(2)     0  ];</span>
0108 <span class="comment">%           H = sparse(H + lambda(2)*diag([2 2 2 2]));</span>
0109 <span class="comment">%</span>
0110 <span class="comment">%     funcs.hessianstructure (optional)</span>
0111 <span class="comment">%</span>
0112 <span class="comment">%     This function serves the same purpose as funcs.jacobianstructure, but</span>
0113 <span class="comment">%     for the Hessian matrix. Again, it is not needed if you are using the</span>
0114 <span class="comment">%     limited-memory quasi-Newton approximation to the Hessian. It takes no</span>
0115 <span class="comment">%     inputs, and must return a sparse, lower triangular matrix. For H&amp;S</span>
0116 <span class="comment">%     test problem #71, the MATLAB callback routine is fairly</span>
0117 <span class="comment">%     straightforward:</span>
0118 <span class="comment">%</span>
0119 <span class="comment">%         function H = hessianstructure()</span>
0120 <span class="comment">%           H = sparse(tril(ones(4)));</span>
0121 <span class="comment">%</span>
0122 <span class="comment">%     funcs.iterfunc (optional)</span>
0123 <span class="comment">%</span>
0124 <span class="comment">%     An additional callback routine that is called once per algorithm</span>
0125 <span class="comment">%     iteration. It takes three inputs: the first is the current iteration</span>
0126 <span class="comment">%     of the algorithm, the second is the current value of the objective,</span>
0127 <span class="comment">%     and the third is a structure containing fields x, inf_pr, inf_du, mu,</span>
0128 <span class="comment">%     d_norm, regularization_size, alpha_du, alpha_pr, and ls_trials. This</span>
0129 <span class="comment">%     function should always return true unless you want IPOPT to terminate</span>
0130 <span class="comment">%     prematurely for whatever reason. If you would like to use the third</span>
0131 <span class="comment">%     input to iterfunc along with auxdata functionality, you will need to</span>
0132 <span class="comment">%     modify the appropriate section of ipopt_auxdata.m.</span>
0133 <span class="comment">%</span>
0134 <span class="comment">%   OPTIONS</span>
0135 <span class="comment">%</span>
0136 <span class="comment">%   The options are passed through the third input. What follows is a</span>
0137 <span class="comment">%   description of the fields you may optionally specify.</span>
0138 <span class="comment">%</span>
0139 <span class="comment">%     options.lb</span>
0140 <span class="comment">%</span>
0141 <span class="comment">%     Specify lower bounds on the variables. It must have the same number</span>
0142 <span class="comment">%     of elements as x0. Set an entry to -Inf to specify no lower bound.</span>
0143 <span class="comment">%</span>
0144 <span class="comment">%     options.ub</span>
0145 <span class="comment">%</span>
0146 <span class="comment">%     Specify upper bounds on the variables. It must have the same number</span>
0147 <span class="comment">%     of elements as x0. Set an entry to Inf to specify no upper bound.</span>
0148 <span class="comment">%</span>
0149 <span class="comment">%     options.cl, options.cu</span>
0150 <span class="comment">%</span>
0151 <span class="comment">%     Set lower and upper bounds on the constraints. Each should be a</span>
0152 <span class="comment">%     vector of length equal to the number of constraints. As before, a</span>
0153 <span class="comment">%     bound is removed by setting the entry to -Inf or +Inf. An equality</span>
0154 <span class="comment">%     constraint is achieved by setting cl(i) = cu(i).</span>
0155 <span class="comment">%</span>
0156 <span class="comment">%     options.auxdata</span>
0157 <span class="comment">%</span>
0158 <span class="comment">%     Optionally, one may choose to pass additional auxiliary data to the</span>
0159 <span class="comment">%     MATLAB callback routines listed above through the function call. For</span>
0160 <span class="comment">%     instance, the objective callback function now takes two inputs, x and</span>
0161 <span class="comment">%     auxdata. The auxiliary data may not change through the course of the</span>
0162 <span class="comment">%     IPOPT optimization. The auxiliary data keep the same values as they</span>
0163 <span class="comment">%     possessed in the initial call. If you need variables that change over</span>
0164 <span class="comment">%     time, you may want to consider global variables (type HELP</span>
0165 <span class="comment">%     GLOBAL). See the lasso.m file in the examples subdirectory for an</span>
0166 <span class="comment">%     illustration of how the auxiliary data is passed to the various</span>
0167 <span class="comment">%     callback functions. Starting with Ipopt version 3.11, you must call</span>
0168 <span class="comment">%     ipopt_auxdata(x0,funcs,options) to use auxdata functionality.</span>
0169 <span class="comment">%</span>
0170 <span class="comment">%     options.zl, options.zu, options.lambda</span>
0171 <span class="comment">%</span>
0172 <span class="comment">%     These fields specify the initial value for the Lagrange multipliers,</span>
0173 <span class="comment">%     which is especially useful for &quot;warm starting&quot; the interior-point</span>
0174 <span class="comment">%     solver. They specify the Lagrange multipliers corresponding to the</span>
0175 <span class="comment">%     lower bounds on the variables, upper bounds on the variables, and</span>
0176 <span class="comment">%     constraints, respectively.</span>
0177 <span class="comment">%</span>
0178 <span class="comment">%     options.ipopt</span>
0179 <span class="comment">%</span>
0180 <span class="comment">%     Finally, you may also change the settings of IPOPT through this</span>
0181 <span class="comment">%     field. For instance, to turn off the IPOPT output, use the</span>
0182 <span class="comment">%     limited-memory BFGS approximation to the Hessian, and turn on the</span>
0183 <span class="comment">%     derivative checker, do the following:</span>
0184 <span class="comment">%</span>
0185 <span class="comment">%       options.ipopt.print_level           = 0;</span>
0186 <span class="comment">%       options.ipopt.hessian_approximation = 'limited-memory';</span>
0187 <span class="comment">%       options.ipopt.derivative_test       = 'first-order';</span>
0188 <span class="comment">%</span>
0189 <span class="comment">%     For more details, see the documentation on the IPOPT website.</span>
0190 <span class="comment">%</span>
0191 <span class="comment">%   OUTPUTS</span>
0192 <span class="comment">%</span>
0193 <span class="comment">%   If the solver successfully converges to a stationary point or terminated</span>
0194 <span class="comment">%   without an unrecoverable error, the function IPOPT outputs the candidate</span>
0195 <span class="comment">%   solution x. In all other cases, an error is thrown. It also outputs some</span>
0196 <span class="comment">%   additional information:</span>
0197 <span class="comment">%</span>
0198 <span class="comment">%     info.zl, info.zu, info.lambda</span>
0199 <span class="comment">%</span>
0200 <span class="comment">%     The value of the Lagrange multipliers at the solution. See the</span>
0201 <span class="comment">%     &quot;options&quot; for more information on the Lagrange multipliers.</span>
0202 <span class="comment">%</span>
0203 <span class="comment">%     info.status</span>
0204 <span class="comment">%</span>
0205 <span class="comment">%     Upon termination, this field will take on one of these following</span>
0206 <span class="comment">%     values (for a more up-to-date listing, see the IpReturnCodes.h header</span>
0207 <span class="comment">%     file in the IPOPT C++ source directory):</span>
0208 <span class="comment">%</span>
0209 <span class="comment">%         0  solved</span>
0210 <span class="comment">%         1  solved to acceptable level</span>
0211 <span class="comment">%         2  infeasible problem detected</span>
0212 <span class="comment">%         3  search direction becomes too small</span>
0213 <span class="comment">%         4  diverging iterates</span>
0214 <span class="comment">%         5  user requested stop</span>
0215 <span class="comment">%</span>
0216 <span class="comment">%        -1  maximum number of iterations exceeded</span>
0217 <span class="comment">%        -2  restoration phase failed</span>
0218 <span class="comment">%        -3  error in step computation</span>
0219 <span class="comment">%       -10  not enough degrees of freedom</span>
0220 <span class="comment">%       -11  invalid problem definition</span>
0221 <span class="comment">%       -12  invalid option</span>
0222 <span class="comment">%       -13  invalid number detected</span>
0223 <span class="comment">%</span>
0224 <span class="comment">%      -100  unrecoverable exception</span>
0225 <span class="comment">%      -101  non-IPOPT exception thrown</span>
0226 <span class="comment">%      -102  insufficient memory</span>
0227 <span class="comment">%      -199  internal error</span>
0228 <span class="comment">%</span>
0229 <span class="comment">%     info.iter, info.cpu</span>
0230 <span class="comment">%</span>
0231 <span class="comment">%     Number of iterations and CPU time (in seconds) taken by the Ipopt run</span>
0232 <span class="comment">%</span>
0233 <span class="comment">%   Finally, for more information, please consult the following webpages:</span>
0234 <span class="comment">%</span>
0235 <span class="comment">%      http://www.cs.ubc.ca/~pcarbo/ipopt-for-matlab</span>
0236 <span class="comment">%      http://projects.coin-or.org/Ipopt</span>
0237 <span class="comment">%</span>
0238 <span class="comment">%   Copyright (C) 2008 Peter Carbonetto. All Rights Reserved.</span>
0239 <span class="comment">%   This code is published under the Eclipse Public License.</span>
0240 <span class="comment">%</span>
0241 <span class="comment">%   Author: Peter Carbonetto</span>
0242 <span class="comment">%           Dept. of Computer Science</span>
0243 <span class="comment">%           University of British Columbia</span>
0244 <span class="comment">%           September 19, 2008</span>
0245 <span class="comment">%</span>
0246 <span class="comment">%   Downloaded binaries from http://www.coin-or.org/download/binary/Ipopt/I</span>
0247 <span class="comment">%   popt-3.11.8-linux64mac64win32win64-matlabmexfiles.zip on 3/22/2016</span></pre></div>
<hr><address><a href="https://e0404.github.io/matRad/" target="_parent"><img src="https://camo.githubusercontent.com/0a593ef6a04757c975b9f4634f6731ea0b019bbd/68747470733a2f2f7261776769742e636f6d2f77696b692f65303430342f6d61745261642f696d616765732f6d61747261645f626c616e6b2e737667" height="12px"/></a> | Generated by  <a href="http://www.artefact.tk/software/matlab/m2html/" target="_parent">m2html</a></strong> &copy; 2005</address>
</body>
</html>